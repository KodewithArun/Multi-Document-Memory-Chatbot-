{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922869f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lama Parser and Retriever Setup\n",
    "from llama_parse import LlamaParse\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "import pandas as pd\n",
    "from pptx import Presentation\n",
    "from langchain_community.document_loaders import (\n",
    "    UnstructuredPDFLoader,\n",
    "    UnstructuredWordDocumentLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredExcelLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    ")\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.retrievers import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"LLAMA_CLOUD_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6736e172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the MultiDoc Memory Chatbot Notebook!\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the MultiDoc Memory Chatbot Notebook!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96eccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading documents from a folder\n",
    "\n",
    "PARSED_FOLDER = Path(\"Parsed_doc\")\n",
    "PARSED_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37cd0733",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_EXTS = [\".pdf\", \".docx\", \".pptx\", \".md\", \".txt\", \".xlsx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ebf0ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_parser = LlamaParse(\n",
    "    api_key=api_key,\n",
    "    result_type=\"markdown\",\n",
    "    verbose=True,\n",
    "    system_prompt=\"Extract structured content and preserve formatting as Markdown.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7258e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_markdown(content: str, filename: str, folder=PARSED_FOLDER):\n",
    "    save_path = folder / filename\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\" Saved {save_path}\")\n",
    "\n",
    "def parse_pdf(file_path: Path):\n",
    "    print(f\"Parsing PDF: {file_path.name}\")\n",
    "    try:\n",
    "        loader = UnstructuredPDFLoader(str(file_path))\n",
    "        docs = loader.load()\n",
    "        text = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        if text.strip():\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"PDF parse error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_docx(file_path: Path):\n",
    "    print(f\"Parsing DOCX with LlamaParse: {file_path.name}\")\n",
    "    try:\n",
    "        parsed = llama_parser.load_data(str(file_path))\n",
    "        text = \"\\n\\n\".join(\n",
    "            part.get(\"text\", \"\") if isinstance(part, dict) else getattr(part, \"text\", getattr(part, \"page_content\", \"\"))\n",
    "            for part in parsed\n",
    "        )\n",
    "        if text.strip():\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"DOCX parse error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_pptx(file_path: Path):\n",
    "    print(f\"Parsing PPTX: {file_path.name}\")\n",
    "    try:\n",
    "        prs = Presentation(str(file_path))\n",
    "        content = \"\"\n",
    "        for i, slide in enumerate(prs.slides, 1):\n",
    "            content += f\"## Slide {i}\\n\"\n",
    "            for shape in slide.shapes:\n",
    "                if hasattr(shape, \"text\") and shape.text.strip():\n",
    "                    content += shape.text.strip() + \"\\n\\n\"\n",
    "        if content.strip():\n",
    "            return content\n",
    "    except Exception as e:\n",
    "        print(f\"PPTX parse error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_xlsx(file_path: Path):\n",
    "    print(f\"Parsing XLSX: {file_path.name}\")\n",
    "    try:\n",
    "        import tabulate\n",
    "    except ImportError:\n",
    "        print(\"Missing 'tabulate' package. Run: pip install tabulate\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        xls = pd.ExcelFile(str(file_path))\n",
    "        content = \"\"\n",
    "        for sheet_name in xls.sheet_names:\n",
    "            df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "            if df.empty:\n",
    "                continue\n",
    "            content += f\"## Sheet: {sheet_name}\\n\\n\"\n",
    "            content += df.to_markdown(index=False) + \"\\n\\n\"\n",
    "        if content.strip():\n",
    "            return content\n",
    "    except Exception as e:\n",
    "        print(f\"XLSX parse error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_md(file_path: Path):\n",
    "    print(f\"Reading Markdown: {file_path.name}\")\n",
    "    try:\n",
    "        text = file_path.read_text(encoding=\"utf-8\")\n",
    "        if text.strip():\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Markdown read error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_txt(file_path: Path):\n",
    "    print(f\"Reading TXT: {file_path.name}\")\n",
    "    try:\n",
    "        text = file_path.read_text(encoding=\"utf-8\")\n",
    "        if text.strip():\n",
    "            return f\"```\\n{text}\\n```\"\n",
    "    except Exception as e:\n",
    "        print(f\"TXT read error: {e}\")\n",
    "    return None\n",
    "\n",
    "def fallback_loader(file_path: Path):\n",
    "    ext = file_path.suffix.lower()\n",
    "    print(f\"Attempting fallback loader for {file_path.name}\")\n",
    "    try:\n",
    "        if ext == \".docx\":\n",
    "            loader = UnstructuredWordDocumentLoader(str(file_path))\n",
    "        elif ext == \".pptx\":\n",
    "            loader = UnstructuredPowerPointLoader(str(file_path))\n",
    "        elif ext == \".xlsx\":\n",
    "            loader = UnstructuredExcelLoader(str(file_path))\n",
    "        elif ext == \".md\":\n",
    "            loader = UnstructuredMarkdownLoader(str(file_path))\n",
    "        elif ext == \".txt\":\n",
    "            loader = TextLoader(str(file_path))\n",
    "        else:\n",
    "            print(f\"No fallback loader available for {file_path.name}\")\n",
    "            return None\n",
    "\n",
    "        docs = loader.load()\n",
    "        text = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "        if text.strip():\n",
    "            print(f\"Fallback loader succeeded for {file_path.name}\")\n",
    "            return text\n",
    "    except Exception as e:\n",
    "        print(f\"Fallback loader error: {e}\")\n",
    "    return None\n",
    "\n",
    "def parse_and_save_file(file_path: Path):\n",
    "    ext = file_path.suffix.lower()\n",
    "    content = None\n",
    "\n",
    "    if ext == \".pdf\":\n",
    "        content = parse_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        content = parse_docx(file_path)\n",
    "    elif ext == \".pptx\":\n",
    "        content = parse_pptx(file_path)\n",
    "    elif ext == \".xlsx\":\n",
    "        content = parse_xlsx(file_path)\n",
    "    elif ext == \".md\":\n",
    "        content = parse_md(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        content = parse_txt(file_path)\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_path.name}\")\n",
    "\n",
    "    # If no content from primary parser, try fallback for all except pdf (which uses unstructured)\n",
    "    if not content and ext != \".pdf\":\n",
    "        content = fallback_loader(file_path)\n",
    "\n",
    "    if content:\n",
    "        save_markdown(content, f\"{file_path.stem}.md\")\n",
    "        return {\"page_content\": content, \"source\": file_path.name}\n",
    "    else:\n",
    "        print(f\"Failed to parse {file_path.name}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87f5bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_parse_folder(folder_path: str):\n",
    "    folder = Path(folder_path)\n",
    "    docs = []\n",
    "    for file_path in folder.glob(\"*\"):\n",
    "        if file_path.suffix.lower() in SUPPORTED_EXTS:\n",
    "            doc = parse_and_save_file(file_path)\n",
    "            if doc:\n",
    "                docs.append(doc)\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_path.name}\")\n",
    "    print(f\"\\nTotal documents parsed and saved: {len(docs)}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c26531b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKS_FOLDER = Path(\"Chunks_doc\")\n",
    "CHUNKS_FOLDER.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f6bdaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def save_chunk(content: str, filename: str):\n",
    "    save_path = CHUNKS_FOLDER / filename\n",
    "    with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "    print(f\"Saved chunk {save_path}\")\n",
    "\n",
    "def split_and_save_chunks(content: str, base_filename: str, chunk_size=1000, chunk_overlap=100):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    chunks = splitter.split_text(content)\n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        chunk_filename = f\"{base_filename}_chunk{i}.md\"\n",
    "        save_chunk(chunk, chunk_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9503e21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing PPTX: day01_workshop.pptx\n",
      " Saved Parsed_doc\\day01_workshop.md\n",
      "Reading Markdown: markdownfile.md\n",
      " Saved Parsed_doc\\markdownfile.md\n",
      "Parsing DOCX with LlamaParse: msword_file.docx\n",
      "Started parsing the file under job_id ccdee811-2f67-44cb-8db2-ffb991a3cdb2\n",
      " Saved Parsed_doc\\msword_file.md\n",
      "Parsing PDF: pdffile.pdf\n",
      "Warning: No languages specified, defaulting to English.\n",
      " Saved Parsed_doc\\pdffile.md\n",
      "Reading TXT: random.txt\n",
      " Saved Parsed_doc\\random.md\n",
      "Parsing XLSX: student_data.xlsx\n",
      " Saved Parsed_doc\\student_data.md\n",
      "\n",
      "Total documents parsed and saved: 6\n"
     ]
    }
   ],
   "source": [
    "# Chunking the documents using RecursiveCharacterTextSplitter\n",
    "# 1. Parse all documents in folder and save full markdowns\n",
    "docs = load_and_parse_folder(\"../data/\")  # adjust path as needed\n",
    "# Change your folder path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45320192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 3 chunks\n",
      "Saved chunk Chunks_doc\\day01_workshop_chunk1.md\n",
      "Saved chunk Chunks_doc\\day01_workshop_chunk2.md\n",
      "Saved chunk Chunks_doc\\day01_workshop_chunk3.md\n",
      "Split into 3 chunks\n",
      "Saved chunk Chunks_doc\\markdownfile_chunk1.md\n",
      "Saved chunk Chunks_doc\\markdownfile_chunk2.md\n",
      "Saved chunk Chunks_doc\\markdownfile_chunk3.md\n",
      "Split into 31 chunks\n",
      "Saved chunk Chunks_doc\\msword_file_chunk1.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk2.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk3.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk4.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk5.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk6.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk7.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk8.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk9.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk10.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk11.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk12.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk13.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk14.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk15.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk16.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk17.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk18.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk19.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk20.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk21.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk22.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk23.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk24.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk25.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk26.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk27.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk28.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk29.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk30.md\n",
      "Saved chunk Chunks_doc\\msword_file_chunk31.md\n",
      "Split into 25 chunks\n",
      "Saved chunk Chunks_doc\\pdffile_chunk1.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk2.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk3.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk4.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk5.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk6.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk7.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk8.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk9.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk10.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk11.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk12.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk13.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk14.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk15.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk16.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk17.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk18.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk19.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk20.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk21.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk22.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk23.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk24.md\n",
      "Saved chunk Chunks_doc\\pdffile_chunk25.md\n",
      "Split into 2 chunks\n",
      "Saved chunk Chunks_doc\\random_chunk1.md\n",
      "Saved chunk Chunks_doc\\random_chunk2.md\n",
      "Split into 3 chunks\n",
      "Saved chunk Chunks_doc\\student_data_chunk1.md\n",
      "Saved chunk Chunks_doc\\student_data_chunk2.md\n",
      "Saved chunk Chunks_doc\\student_data_chunk3.md\n"
     ]
    }
   ],
   "source": [
    "# 2. Split each parsed document into chunks and save chunks\n",
    "for doc in docs:\n",
    "    content = doc[\"page_content\"]\n",
    "    source_name = doc[\"source\"]\n",
    "    base_name = source_name.rsplit(\".\", 1)[0]  # Remove extension\n",
    "    split_and_save_chunks(content, base_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45ea7cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arunp\\AppData\\Local\\Temp\\ipykernel_12412\\611479137.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Folder with chunk files\n",
    "CHUNKS_FOLDER = Path(\"Chunks_doc\")\n",
    "\n",
    "# Initialize HuggingFace embedding model\n",
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63597554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 69 chunks.\n",
      "Chroma vectorstore created and populated.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load chunk documents\n",
    "chunk_docs = []\n",
    "for chunk_file in CHUNKS_FOLDER.glob(\"*.md\"):\n",
    "    text = chunk_file.read_text(encoding=\"utf-8\")\n",
    "    chunk_docs.append(Document(page_content=text, metadata={\"source\": chunk_file.name}))\n",
    "\n",
    "print(f\"Loaded {len(chunk_docs)} chunks.\")\n",
    "\n",
    "# Initialize Chroma vectorstore (persists to ./chromadb/)\n",
    "vectorstore = Chroma.from_documents(documents=chunk_docs, embedding=embeddings, collection_name=\"my_docs\",persist_directory=\"./chromadb/\")\n",
    "\n",
    "print(\"Chroma vectorstore created and populated.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b2814d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 (source: msword_file_chunk32.md):\n",
      "### How It Makes E-Commerce Better\n",
      "- **Detailed Product Information**: E-commerce sites offer extensive details (e.g., specifications, reviews, comparisons) that help customers make informed decisions.\n",
      "- **Price Transparency**: Customers can compare prices across multiple sellers instantly, ensuring they get the best deal.\n",
      "- **Real-Time Updates**: Businesses can update stock, prices, or promotions instantly, keeping information current.\n",
      "- **Customer Insights for Businesses**: E-commerce platform...\n",
      "---\n",
      "\n",
      "Result 2 (source: msword_file_chunk32.md):\n",
      "### How It Makes E-Commerce Better\n",
      "- **Detailed Product Information**: E-commerce sites offer extensive details (e.g., specifications, reviews, comparisons) that help customers make informed decisions.\n",
      "- **Price Transparency**: Customers can compare prices across multiple sellers instantly, ensuring they get the best deal.\n",
      "- **Real-Time Updates**: Businesses can update stock, prices, or promotions instantly, keeping information current.\n",
      "- **Customer Insights for Businesses**: E-commerce platform...\n",
      "---\n",
      "\n",
      "Result 3 (source: msword_file_chunk32.md):\n",
      "### How It Makes E-Commerce Better\n",
      "- **Detailed Product Information**: E-commerce sites offer extensive details (e.g., specifications, reviews, comparisons) that help customers make informed decisions.\n",
      "- **Price Transparency**: Customers can compare prices across multiple sellers instantly, ensuring they get the best deal.\n",
      "- **Real-Time Updates**: Businesses can update stock, prices, or promotions instantly, keeping information current.\n",
      "- **Customer Insights for Businesses**: E-commerce platform...\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query example\n",
    "query = \"Explain management principles\"\n",
    "\n",
    "results = vectorstore.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"Result {i} (source: {doc.metadata['source']}):\\n{doc.page_content[:500]}...\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb5df81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76c8f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(name=\"source\", description=\"Name of the document file\", type=\"string\"),\n",
    "    AttributeInfo(name=\"file_type\", description=\"Type of file, like pdf, docx, pptx\", type=\"string\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894abb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec3cfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model=\"llama3-8b-8192\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599c7d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32bf576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Content of documents which may include PDFs, Word files, slides, and text containing varied topics.\"\n",
    "\n",
    "\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectorstore,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79e96dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "922cb9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema.runnable import RunnableSequence, RunnableLambda\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.memory.chat_message_histories import FileChatMessageHistory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b8962f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Define chat prompt with conversation history placeholder\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"You are a highly reliable assistant helping users understand documents. \"\n",
    "        \"Always answer ONLY using the provided context and conversation history. \"\n",
    "        \"If the answer is not present in the context, clearly state that you do not know or that the information is not available. \"\n",
    "        \"Do NOT make up or infer facts that are not explicitly in the context.\"\n",
    "    ),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "    ),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8179a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8a51a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Function to format retrieved docs into a single string\n",
    "def format_docs(docs):\n",
    "    if isinstance(docs, list):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    raise ValueError(\"Expected a list of Document objects.\")\n",
    "\n",
    "# %% Build the retrieval chain, now passing the 'history' along\n",
    "retrieval_chain = RunnableSequence(\n",
    "    {\n",
    "        \"context\": RunnableLambda(lambda x: x[\"question\"]) | retriever | RunnableLambda(format_docs),\n",
    "        \"question\": RunnableLambda(lambda x: x[\"question\"]),\n",
    "        \"history\": RunnableLambda(lambda x: x.get(\"history\", [])),  # Pass chat history\n",
    "    }\n",
    "    | qa_prompt\n",
    "    | llm\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f84fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"memory\", exist_ok=True)\n",
    "\n",
    "def get_file_history(session_id: str) -> FileChatMessageHistory:\n",
    "    file_path = f\"memory/{session_id}.json\"\n",
    "    return FileChatMessageHistory(file_path=file_path)\n",
    "\n",
    "\n",
    "# %% Wrap chain with memory support\n",
    "retrieval_chain_with_memory = RunnableWithMessageHistory(\n",
    "    runnable=retrieval_chain,\n",
    "    get_message_history=get_file_history,\n",
    "    get_session_history=get_file_history,  # add this!\n",
    "    input_messages_key=\"question\",\n",
    "    history_messages_key=\"history\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "530abc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, a MicroController is a highly integrated device that includes, on one chip, all or most of the parts needed to perform an application control function. It has bit manipulation instructions, easy and direct access to I/O, and quick and efficient interrupt processing.\n"
     ]
    }
   ],
   "source": [
    "# %% Helper function to run queries easily with session memory\n",
    "def chat_with_memory(question: str, session_id: str = \"default_session\"):\n",
    "    result = retrieval_chain_with_memory.invoke(\n",
    "        {\"question\": question},\n",
    "        config={\"configurable\": {\"session_id\": session_id}},\n",
    "    )\n",
    "    return result\n",
    "\n",
    "# %% Run a sample question and print response\n",
    "response = chat_with_memory(\"What is MicroController?\", session_id=\"user123\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b366b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but the provided context does not mention MicroController. It appears to be discussing Photo and Video Sharing Platforms, specifically Instagram, YouTube, and Snapchat, and their role in e-commerce.\n"
     ]
    }
   ],
   "source": [
    "# %% Run a sample question and print response\n",
    "response = chat_with_memory(\"Explain it more?\", session_id=\"user123\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55a8b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, a microcontroller is a highly integrated device that combines multiple components onto a single chip. This includes processing, memory, and input/output (I/O) components. The text highlights the key features of a microcontroller, including:\n",
      "\n",
      "1. Bit manipulation instructions: Microcontrollers can perform bit-level operations, which enables them to efficiently manipulate digital signals.\n",
      "2. Easy and direct access to I/O: Microcontrollers have direct access to input/output components, making it easy to interact with external devices and sensors.\n",
      "3. Quick and efficient interrupt processing: Microcontrollers can quickly respond to interrupts, which enables them to efficiently handle events and changes in the system.\n",
      "\n",
      "The miniaturization process has made it possible to fit all the necessary components onto a single chip, which is much smaller and more cost-effective than traditional methods.\n"
     ]
    }
   ],
   "source": [
    "# %% Run a sample question and print response\n",
    "response = chat_with_memory(\"What is microcontroller explain?\", session_id=\"user123\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4f7f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm afraid I don't see your name, Arunb, in the provided document. It seems that the document only contains information about students with IDs 1001 to 1004, and their names are Alice Johnson, Bob Smith, Clara Davis, and David Wilson. I don't know your name or any other information about you as it's not present in the given context.\n"
     ]
    }
   ],
   "source": [
    "response= chat_with_memory(\"My name is Arunb\", session_id=\"user124\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8258baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I don't see your name in the provided context. The only name mentioned is Emma Moore. I don't know your name as it's not present in the given document.\n"
     ]
    }
   ],
   "source": [
    "response= chat_with_memory(\"What is my name \", session_id=\"user124\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4c747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".multidocbotenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
